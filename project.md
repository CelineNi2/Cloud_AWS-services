# Context of the project

Your group has been hired to provide a solution to summarize and consolidate the data of the daily sales generated by the stores of a large retailer. The stores are geographically distributed all over the world and the headquarter is located in Saint-Étienne. The retailer prefers to use a Pubic Cloud infrastructure rather than purchase, install, and maintain all the required infrastructure.

The stores generate a comma separated values (CSV) file containing their sales everyday [Sample Files](https://ci.mines-stetienne.fr/cps2/course/cloud/data/sales-data.zip).

The group’s task is to propose a solution architecture using the AWS services to support three applications: Client, Worker, Consolidator.

The Client application is used independently by each store. The application uploads the daily file passed as parameter into the Cloud storage and notify the Worker application.

The Worker application reads the CSV file and summarizes the daily sales by store and by product.

By Store

Total profit

By Product

Total quantity

Total sold

Total profit

The summarized result should be stored in a new CSV file in the Cloud storage.

The Consolidator application is executed manually once the operator detects that the summary files of all stores have been processed. The operator passes the date of the files to be processed as argument to the application. The application reads the summary results from the files of that date and displays the total retailer’s profit, the most and least profitable stores, and the total quantity, total sold, and total profit per product.

NOTE
The detection that the summary files of all stores has been processed is done by manual inspection. It is NOT required to automate this task.
Additional Requirements
The Worker must be implemented as a Lambda function and as a Java application able to run in a Linux VM

The two implementations should be quantitatively compared using the Sample Files

The solution must guarantee the processing of the daily sales files in case of the Workers unavailability or busyness

The solution must use the least amount of Cloud storage resources possible

The Worker must process as soon as possible new daily sales files


## Description of the work that has been done

For this project, I separated the 3 main tasks within different folder and java class for it to be easier to use.
The Client part uses the Amazon S3 service to store and share the data with the other stores, as well as the Amazon SQS queue service to notify the system whenever a file has been added. Then the lambdaWorker.java file implements a AWS Lambda function that combined with the SQS queue as a trigger, would run the handleRequest function when the SQS queue receive a notification (when a file has been added). That would create or update the file that serves to analyse the profits made by the company. Then at last, the final results can be observed either by running the Consolidator.java file, or by doing so on a virtual EC2 machine.

As you can see, there are 2 implementations for the worker. The first one Worker is implemented as a programm one had to run by itself whenever a file has been added in the Amazon S3 bucket. The second one, lambdaWorker is the implementation that can be handled by the AWS lambda service, automating the worker's tasks. 